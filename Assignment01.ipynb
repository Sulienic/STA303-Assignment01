{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 01: Multi-class Classification \n",
    "In this Assignment, you will train a deep model on the CIFAR10 from the scratch using PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "SEED = 1 \n",
    "NUM_CLASS = 10\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 30\n",
    "EVAL_INTERVAL=1\n",
    "SAVE_DIR = './log'\n",
    "\n",
    "# Optimizer\n",
    "LEARNING_RATE = 1e-1\n",
    "MOMENTUM = 0.9\n",
    "STEP=5\n",
    "GAMMA=0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# cifar10 transform\n",
    "transform_cifar10_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_cifar10_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='../data', train=True,\n",
    "                                        download=True, transform=transform_cifar10_train)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=16)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root='../data', train=False,\n",
    "                                       download=True, transform=transform_cifar10_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=16)\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 4, 3)  \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(4, 8, 3)  \n",
    "        self.fc1 = nn.Linear(8 * 6 * 6, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 8 * 6 * 6)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, alpha=None):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        # Compute the softmax activation along the channel dimension\n",
    "        logpt = F.log_softmax(input, dim=1)\n",
    "        \n",
    "        # Gather the log probabilities at the target index\n",
    "        logpt = logpt.gather(1, target.view(-1, 1))\n",
    "        logpt = logpt.view(-1)\n",
    "        \n",
    "        # Compute the PT term\n",
    "        pt = torch.exp(logpt)\n",
    "        \n",
    "        # Compute the Focal Loss\n",
    "        loss = -((1 - pt) ** self.gamma) * logpt\n",
    "        \n",
    "        # Apply class-wise weights (alpha)\n",
    "        if self.alpha is not None:\n",
    "            alpha = self.alpha.gather(0, target.view(-1))\n",
    "            loss = alpha * loss\n",
    "        \n",
    "        return loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv1): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=288, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ConvNet()\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP, gamma=GAMMA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: per batch training/testing\n",
    "---\n",
    "\n",
    "Please denfine two function named ``train_batch`` and ``test_batch``. These functions are essential for training and evaluating machine learning models using batched data from dataloaders.\n",
    "\n",
    "**To do**: \n",
    "1. Define the loss function i.e [nn.CrossEntropyLoss()](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html).\n",
    "2. Take the image as the input and generate the output using the pre-defined SimpleNet.\n",
    "3. Calculate the loss between the output and the corresponding label using the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Write your answer here ##################\n",
    "# Define the loss function\n",
    "criterion_MAE = nn.L1Loss() \n",
    "criterion_CE = nn.CrossEntropyLoss()\n",
    "criterion_Focal1 = FocalLoss(gamma = 0.5)\n",
    "criterion_Focal2 = FocalLoss(gamma = 2)\n",
    "\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(model, image, target):\n",
    "    output = model(image)\n",
    "    #loss = criterion_MAE(output.T, target)\n",
    "    loss = criterion_CE(output, target)\n",
    "    #loss = criterion_Focal1(output, target.clone().detach())\n",
    "    #loss = criterion_Focal2(output, target.clone().detach())\n",
    "    return output, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_batch(model, image, target):\n",
    "    output = model(image)\n",
    "    #loss = criterion_MAE(output.T, target)\n",
    "    loss = criterion_CE(output, target)\n",
    "    #loss = criterion_Focal1(output, target.clone().detach())\n",
    "    #loss = criterion_Focal2(output, target.clone().detach())\n",
    "    return output, loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_results(train_loss, test_loss, train_acc, test_acc):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    "    \n",
    "    # Training Loss vs. Testing Loss\n",
    "    axes[0][0].plot(train_loss, label='Training Loss')\n",
    "    axes[0][0].plot(test_loss, label='Testing Loss')\n",
    "    axes[0][0].set_title('Training vs. Testing Loss')\n",
    "    axes[0][0].set_xlabel('Epoch')\n",
    "    axes[0][0].set_ylabel('Loss')\n",
    "    axes[0][0].legend()\n",
    "    \n",
    "    # Training Accuracy vs. Testing Accuracy\n",
    "    axes[0][1].plot(train_acc, label='Training Accuracy')\n",
    "    axes[0][1].plot(test_acc, label='Testing Accuracy')\n",
    "    axes[0][1].set_title('Training vs. Testing Accuracy')\n",
    "    axes[0][1].set_xlabel('Epoch')\n",
    "    axes[0][1].set_ylabel('Accuracy')\n",
    "    axes[0][1].legend()\n",
    "    \n",
    "    # Training Loss\n",
    "    axes[1][0].plot(train_loss)\n",
    "    axes[1][0].set_title('Training Loss')\n",
    "    axes[1][0].set_xlabel('Epoch')\n",
    "    axes[1][0].set_ylabel('Loss')\n",
    "    \n",
    "    # Training Accuracy\n",
    "    axes[1][1].plot(train_acc)\n",
    "    axes[1][1].set_title('Training Accuracy')\n",
    "    axes[1][1].set_xlabel('Epoch')\n",
    "    axes[1][1].set_ylabel('Accuracy')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results_CE_2.png')\n",
    "    #plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m running_cls_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     15\u001b[0m running_cls_corrects \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (image, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n\u001b[1;32m     19\u001b[0m     image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     20\u001b[0m     target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:1330\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1328\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_data()\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, _utils\u001b[38;5;241m.\u001b[39mworker\u001b[38;5;241m.\u001b[39m_IterableDatasetStopIteration):\n\u001b[1;32m   1333\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent_workers:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_loss = []\n",
    "training_acc = []\n",
    "testing_loss = []\n",
    "testing_acc = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    ##########################\n",
    "    ### Training\n",
    "    ##########################\n",
    "\n",
    "    running_cls_loss = 0.0\n",
    "    running_cls_corrects = 0\n",
    "\n",
    "    for batch_idx, (image, target) in enumerate(train_dataloader):\n",
    "\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # train model\n",
    "        outputs, loss = train_batch(model, image, target)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        \n",
    "        loss_data = loss.data.item()\n",
    "        if np.isnan(loss_data):\n",
    "            raise ValueError('loss is nan while training')\n",
    "        running_cls_loss += loss.item()\n",
    "        running_cls_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    epoch_loss = running_cls_loss / len(train_set)\n",
    "    epoch_acc = running_cls_corrects.double() / len(train_set)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}/{NUM_EPOCHS} Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "    training_loss.append(epoch_loss)\n",
    "    training_acc.append(epoch_acc.cpu().detach().numpy())\n",
    "\n",
    "    # change learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "\n",
    "    ##########################\n",
    "    ### Testing\n",
    "    ##########################\n",
    "    # # eval model during training or in the last epoch\n",
    "    if (epoch + 1) % EVAL_INTERVAL == 0 or (epoch +1) == NUM_EPOCHS:\n",
    "        print('Begin test......')\n",
    "        model.eval()\n",
    "    \n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "\n",
    "        for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "\n",
    "            image = image.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # test model\n",
    "            outputs, loss = test_batch(model, image, target)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            val_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "        val_loss = val_loss / len(test_set)\n",
    "        val_acc = val_corrects.double() / len(test_set)\n",
    "        print(f'Test Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
    "        testing_loss.append(val_loss)\n",
    "        testing_acc.append(val_acc.cpu().detach().numpy())\n",
    "\n",
    "        # save the model in last epoch\n",
    "        if (epoch +1) == NUM_EPOCHS:\n",
    "            \n",
    "            state = {\n",
    "            'state_dict': model.state_dict(),\n",
    "            'acc': epoch_acc,\n",
    "            'epoch': (epoch+1),\n",
    "            }\n",
    "\n",
    "            # check the dir\n",
    "            if not os.path.exists(SAVE_DIR):\n",
    "                os.makedirs(SAVE_DIR)\n",
    "\n",
    "            # save the state\n",
    "            torch.save(state, osp.join(SAVE_DIR, 'checkpoint_%s.pth' % (str(epoch+1))))\n",
    "plot_results(training_loss, testing_loss, training_acc, testing_acc)\n",
    "plt.savefig('results_CE_2.png')\n",
    "\n",
    "import pandas as pd\n",
    "data = {\n",
    "    'Epoch': range(1, len(training_loss)+1),\n",
    "    'Training Loss': training_loss,\n",
    "    'Testing Loss': testing_loss,\n",
    "    'Training Accuracy': training_acc,\n",
    "    'Testing Accuracy': testing_acc\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "# 进行数据分析，例如计算均值、标准差等\n",
    "mean_train_loss = df['Training Loss'].mean()\n",
    "mean_test_loss = df['Testing Loss'].mean()\n",
    "mean_train_acc = df['Training Accuracy'].mean()\n",
    "mean_test_acc = df['Testing Accuracy'].mean()\n",
    "\n",
    "std_train_loss = df['Training Loss'].std()\n",
    "std_test_loss = df['Testing Loss'].std()\n",
    "std_train_acc = df['Training Accuracy'].std()\n",
    "std_test_acc = df['Testing Accuracy'].std()\n",
    "\n",
    "print(\"Mean Training Loss:\", mean_train_loss)\n",
    "print(\"Mean Testing Loss:\", mean_test_loss)\n",
    "print(\"Mean Training Accuracy:\", mean_train_acc)\n",
    "print(\"Mean Testing Accuracy:\", mean_test_acc)\n",
    "print(\"Standard Deviation of Training Loss:\", std_train_loss)\n",
    "print(\"Standard Deviation of Testing Loss:\", std_test_loss)\n",
    "print(\"Standard Deviation of Training Accuracy:\", std_train_acc)\n",
    "print(\"Standard Deviation of Testing Accuracy:\", std_test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = {\n",
    "    'Epoch': range(1, len(training_loss)+1),\n",
    "    'Training Loss': training_loss,\n",
    "    'Testing Loss': testing_loss,\n",
    "    'Training Accuracy': training_acc,\n",
    "    'Testing Accuracy': testing_acc\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "styled_df = df.style.format({\n",
    "    \"Training Loss\": \"{:.4f}\",\n",
    "    \"Testing Loss\": \"{:.4f}\",\n",
    "    \"Training Accuracy\": \"{:.2%}\",\n",
    "    \"Testing Accuracy\": \"{:.2%}\"\n",
    "})\n",
    "display(styled_df)\n",
    "df.to_csv(path_or_buf='CE_2.csv', float_format='%.4f')\n",
    "\n",
    "# 进行数据分析，例如计算均值、标准差等\n",
    "mean_train_loss = df['Training Loss'].mean()\n",
    "mean_test_loss = df['Testing Loss'].mean()\n",
    "mean_train_acc = df['Training Accuracy'].mean()\n",
    "mean_test_acc = df['Testing Accuracy'].mean()\n",
    "\n",
    "std_train_loss = df['Training Loss'].std()\n",
    "std_test_loss = df['Testing Loss'].std()\n",
    "std_train_acc = df['Training Accuracy'].std()\n",
    "std_test_acc = df['Testing Accuracy'].std()\n",
    "\n",
    "# 创建包含统计结果的数据框\n",
    "stats_data = {\n",
    "    'Training Loss': [mean_train_loss, std_train_loss],\n",
    "    'Testing Loss': [mean_test_loss, std_test_loss],\n",
    "    'Training Accuracy': [mean_train_acc, std_train_acc],\n",
    "    'Testing Accuracy': [mean_test_acc, std_test_acc]\n",
    "}\n",
    "stats_df = pd.DataFrame(stats_data, index=['Mean', 'Std'])\n",
    "\n",
    "styled_stats_df = stats_df.style.format({\n",
    "    \"Training Loss\": \"{:.4f}\",\n",
    "    \"Testing Loss\": \"{:.4f}\",\n",
    "    \"Training Accuracy\": \"{:.2%}\",\n",
    "    \"Testing Accuracy\": \"{:.2%}\"\n",
    "})\n",
    "\n",
    "# 输出统计数据框\n",
    "display(styled_stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Instance inference\n",
    "---\n",
    "The task is to visualizes an image along with model prediction and class probabilities.\n",
    "\n",
    "**To do**: \n",
    "1. Calculate the prediction and the probabilities for each class.\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, classes = next(iter(test_dataloader))\n",
    "input = inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Write your answer here ##################\n",
    "# input: image, model\n",
    "# outputs: predict_label, probabilities\n",
    "# predict_label is the index (or label) of the class with the highest probability from the probabilities.\n",
    "############################################################### \n",
    "output = model(input.to('cuda'))\n",
    "probabilities = torch.softmax(output, dim=1).cpu()\n",
    "_, predict_label = torch.max(probabilities, 1)\n",
    "probabilities = probabilities.cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print probabilities for each class:\n",
      "airplane: 0.1005\n",
      "automobile: 0.0998\n",
      "bird: 0.1000\n",
      "cat: 0.0999\n",
      "deer: 0.0994\n",
      "dog: 0.1002\n",
      "frog: 0.1005\n",
      "horse: 0.0990\n",
      "ship: 0.1006\n",
      "truck: 0.1001\n"
     ]
    }
   ],
   "source": [
    "predicted_class = class_names[predict_label.item()]\n",
    "predicted_probability = probabilities[0][predict_label].item()\n",
    "image = input.numpy().transpose((1, 2, 0))\n",
    "plt.imshow(image)\n",
    "plt.text(17, 30, f'Predicted Class: {predicted_class}\\nProbability: {predicted_probability:.2f}', \n",
    "            color='white', backgroundcolor='black', fontsize=8)\n",
    "plt.show()\n",
    "# Print probabilities for each class\n",
    "probability = {}\n",
    "print('Print probabilities for each class:')\n",
    "for i in range(len(class_names)):\n",
    "    print(f'{class_names[i]}: {probabilities[0][i].item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
